{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L:\\Anaconda3\\envs\\PT\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import env.AirSimClient as AirSimClient\n",
    "import time\n",
    "from env.EnvImgConrtol import EnvImgControl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IMGDQN.RL_net import DQNClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IMGDQN.model import get_model\n",
    "test_model = get_model(2,0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {}\n",
    "\n",
    "settings[\"learning_rate\"] = 0.003\n",
    "settings[\"reward_decay\"] = 0.9\n",
    "settings[\"e_greedy\"] = 0.99\n",
    "settings[\"e_greedy_increasement\"] = 0.0003\n",
    "settings[\"memory_size\"] = 81920\n",
    "settings[\"batch_size\"] = 32\n",
    "settings[\"epochs\"] = 1\n",
    "settings[\"replace_target_iter\"] = 50\n",
    "settings[\"model\"] = test_model\n",
    "settings[\"n_actions\"] = 2\n",
    "\n",
    "#settings[\"model\"] = keras.models.load_model(\"temp/IMG.h5\")\n",
    "RL = DQNClass(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for connection: \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 50)        614450    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 204800)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                10240050  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 10,854,602\n",
      "Trainable params: 10,854,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env = EnvImgControl()\n",
    "RL.model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset due to  too high  Episode reward:  62.3408203125 total success: 0 of 1       \n",
      "reset due to  too high  Episode reward:  -15.38134765625 total success: 0 of 2     \n",
      "reset due to  too high  Episode reward:  -8.0732421875 total success: 0 of 3       \n",
      "reset due to  collision  Episode reward:  -92.1845703125 total success: 0 of 4     \n",
      "reset due to  collision  Episode reward:  -66.1396484375 total success: 0 of 5     \n",
      "reset due to  collision  Episode reward:  -61.7884521484375 total success: 0 of 6  \n",
      "reset due to  too high  Episode reward:  -7.1572265625 total success: 0 of 7       \n",
      "reset due to  too high  Episode reward:  -27.4349365234375 total success: 0 of 8   \n",
      "reset due to  too high  Episode reward:  -17.435546875 total success: 0 of 9       \n",
      "reset due to  too high  Episode reward:  -27.25927734375 total success: 0 of 10    \n",
      "reset due to  collision  Episode reward:  -23.4443359375 total success: 0 of 11    \n",
      "reset due to  collision  Episode reward:  -26.53369140625 total success: 0 of 12   \n",
      "reset due to  collision  Episode reward:  -62.73291015625 total success: 0 of 13   \n",
      "reset due to  collision  Episode reward:  -63.8184814453125 total success: 0 of 14 \n",
      "reset due to  collision  Episode reward:  16.313720703125 total success: 0 of 15   \n",
      "reset due to  collision  Episode reward:  -25.1317138671875 total success: 0 of 16 \n",
      "reset due to  collision  Episode reward:  -65.43017578125 total success: 0 of 17   \n",
      "reset due to  collision  Episode reward:  -24.83154296875 total success: 0 of 18   \n",
      "reset due to  too high  Episode reward:  -3.591796875 total success: 0 of 19       \n",
      "reset due to  too high  Episode reward:  0.25 total success: 0 of 20               \n",
      "reset due to  too high  Episode reward:  -39.82373046875 total success: 0 of 21    \n",
      "reset due to  too high  Episode reward:  -50.423828125 total success: 0 of 22      \n",
      "reset due to  too high  Episode reward:  -60.369140625 total success: 0 of 23      \n",
      "reset due to  too high  Episode reward:  -40.22265625 total success: 0 of 24       \n",
      "reset due to  too high  Episode reward:  -65.5341796875 total success: 0 of 25     \n",
      "reset due to  collision  Episode reward:  -64.80078125 total success: 0 of 26      \n",
      "reset due to  collision  Episode reward:  -93.8779296875 total success: 0 of 27    \n",
      "reset due to  collision  Episode reward:  -61.1904296875 total success: 0 of 28    \n",
      "reset due to  collision  Episode reward:  -64.080078125 total success: 0 of 29     \n",
      "reset due to  collision  Episode reward:  -56.306396484375 total success: 0 of 30  \n",
      "reset due to  collision  Episode reward:  -61.56591796875 total success: 0 of 31   \n",
      "reset due to  collision  Episode reward:  -64.31640625 total success: 0 of 32      \n",
      "reset due to  collision  Episode reward:  -63.58251953125 total success: 0 of 33   \n",
      "reset due to  too high  Episode reward:  -53.103515625 total success: 0 of 34      \n",
      "reset due to  too high  Episode reward:  -55.16015625 total success: 0 of 35       \n",
      "reset due to  too high  Episode reward:  -46.75390625 total success: 0 of 36       \n",
      "reset due to  too high  Episode reward:  -55.3701171875 total success: 0 of 37     \n",
      "reset due to  too high  Episode reward:  -64.22607421875 total success: 0 of 38    \n",
      "reset due to  too high  Episode reward:  -30.478515625 total success: 0 of 39      \n",
      "reset due to  too high  Episode reward:  -45.7236328125 total success: 0 of 40     \n",
      "reset due to  too high  Episode reward:  -56.767578125 total success: 0 of 41      \n",
      "reset due to  too high  Episode reward:  -55.2861328125 total success: 0 of 42     \n",
      "reset due to  too high  Episode reward:  -70.4404296875 total success: 0 of 43     \n",
      "reset due to  too high  Episode reward:  -52.4912109375 total success: 0 of 44     \n",
      "reset due to  too high  Episode reward:  -51.73828125 total success: 0 of 45       \n",
      "reset due to  too high  Episode reward:  -70.498046875 total success: 0 of 46      \n",
      "reset due to  too high  Episode reward:  -51.7646484375 total success: 0 of 47     \n",
      "reset due to  too high  Episode reward:  -59.31884765625 total success: 0 of 48    \n",
      "reset due to  too high  Episode reward:  -58.4775390625 total success: 0 of 49     \n",
      "reset due to  too high  Episode reward:  -61.4384765625 total success: 0 of 50     \n",
      "reset due to  too high  Episode reward:  -67.35009765625 total success: 0 of 51    \n",
      "reset due to  too high  Episode reward:  -70.4560546875 total success: 0 of 52     \n",
      "reset due to  too high  Episode reward:  -71.296875 total success: 0 of 53         \n",
      "reset due to  too high  Episode reward:  -75.359375 total success: 0 of 54         \n",
      "reset due to  too high  Episode reward:  -70.6904296875 total success: 0 of 55     \n",
      "reset due to  too high  Episode reward:  -40.41015625 total success: 0 of 56       \n",
      "reset due to  too high  Episode reward:  -64.244140625 total success: 0 of 57      \n",
      "reset due to  too high  Episode reward:  -73.4169921875 total success: 0 of 58     \n",
      "reset due to  too high  Episode reward:  -72.13525390625 total success: 0 of 59    \n",
      "reset due to  too high  Episode reward:  -75.478515625 total success: 0 of 60      \n",
      "reset due to  too high  Episode reward:  -65.26953125 total success: 0 of 61       \n",
      "reset due to  too high  Episode reward:  -75.3232421875 total success: 0 of 62     \n",
      "reset due to  too high  Episode reward:  -75.4150390625 total success: 0 of 63     \n",
      "reset due to  too high  Episode reward:  -65.4775390625 total success: 0 of 64     \n",
      "reset due to  too high  Episode reward:  -75.4794921875 total success: 0 of 65     \n",
      "reset due to  too high  Episode reward:  -71.1396484375 total success: 0 of 66     \n",
      "reset due to  too high  Episode reward:  -75.41015625 total success: 0 of 67       \n",
      "reset due to  too high  Episode reward:  -75.3916015625 total success: 0 of 68     \n",
      "reset due to  collision  Episode reward:  -61.2994384765625 total success: 0 of 69 \n",
      "reset due to  collision  Episode reward:  -62.0712890625 total success: 0 of 70    \n",
      "reset due to  collision  Episode reward:  -59.88037109375 total success: 0 of 71   \n",
      "reset due to  collision  Episode reward:  -58.444091796875 total success: 0 of 72  \n",
      "reset due to  collision  Episode reward:  -61.48193359375 total success: 0 of 73   \n",
      "reset due to  collision  Episode reward:  -60.292724609375 total success: 0 of 74  \n",
      "reset due to  collision  Episode reward:  -60.89404296875 total success: 0 of 75   \n",
      "reset due to  collision  Episode reward:  -59.078369140625 total success: 0 of 76  \n",
      "reset due to  collision  Episode reward:  -57.46533203125 total success: 0 of 77   \n",
      "reset due to  collision  Episode reward:  -60.255859375 total success: 0 of 78     \n",
      "reset due to  collision  Episode reward:  -54.61279296875 total success: 0 of 79   \n",
      "reset due to  collision  Episode reward:  -60.578125 total success: 0 of 80        \n",
      "reset due to  collision  Episode reward:  -59.791015625 total success: 0 of 81     \n",
      "reset due to  collision  Episode reward:  -57.6171875 total success: 0 of 82       \n",
      "reset due to  collision  Episode reward:  -57.08544921875 total success: 0 of 83   \n",
      "reset due to  collision  Episode reward:  -61.4853515625 total success: 0 of 84    \n",
      "reset due to  collision  Episode reward:  -60.17626953125 total success: 0 of 85   \n",
      "reset due to  collision  Episode reward:  -53.736572265625 total success: 0 of 86  \n",
      "reset due to  collision  Episode reward:  -60.35693359375 total success: 0 of 87   \n",
      "reset due to  collision  Episode reward:  -63.1220703125 total success: 0 of 88    \n",
      "reset due to  collision  Episode reward:  -59.698486328125 total success: 0 of 89  \n",
      "reset due to  collision  Episode reward:  -61.1474609375 total success: 0 of 90    \n",
      "reset due to  collision  Episode reward:  -60.31396484375 total success: 0 of 91   \n",
      "reset due to  collision  Episode reward:  -60.71484375 total success: 0 of 92      \n",
      "reset due to  collision  Episode reward:  -60.21533203125 total success: 0 of 93   \n",
      "reset due to  collision  Episode reward:  -61.767578125 total success: 0 of 94     \n",
      "reset due to  collision  Episode reward:  -62.0234375 total success: 0 of 95       \n",
      "reset due to  collision  Episode reward:  -59.708740234375 total success: 0 of 96  \n",
      "reset due to  collision  Episode reward:  -61.835205078125 total success: 0 of 97  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset due to  collision  Episode reward:  -57.62255859375 total success: 0 of 98   \n",
      "reset due to  collision  Episode reward:  -58.86962890625 total success: 0 of 99   \n",
      "reset due to  too high  Episode reward:  -48.1806640625 total success: 0 of 100    \n",
      "reset due to  too high  Episode reward:  -75.4658203125 total success: 0 of 101    \n",
      "reset due to  collision  Episode reward:  -64.91552734375 total success: 0 of 102  \n",
      "reset due to  collision  Episode reward:  -61.796630859375 total success: 0 of 103 \n",
      "reset due to  too high  Episode reward:  -67.0166015625 total success: 0 of 104    \n",
      "reset due to  too high  Episode reward:  -75.2919921875 total success: 0 of 105    \n",
      "reset due to  too high  Episode reward:  -74.939453125 total success: 0 of 106     \n",
      "reset due to  too high  Episode reward:  -75.4833984375 total success: 0 of 107    \n",
      "reset due to  too high  Episode reward:  -70.345703125 total success: 0 of 108     \n",
      "reset due to  too high  Episode reward:  -75.4619140625 total success: 0 of 109    \n",
      "reset due to  too high  Episode reward:  -75.3955078125 total success: 0 of 110    \n",
      "reset due to  too high  Episode reward:  -75.33203125 total success: 0 of 111      \n",
      "reset due to  too high  Episode reward:  -77.3896484375 total success: 0 of 112    \n",
      "reset due to  too high  Episode reward:  -75.33203125 total success: 0 of 113      \n",
      "reset due to  too high  Episode reward:  -75.3779296875 total success: 0 of 114    \n",
      "reset due to  too high  Episode reward:  -75.3564453125 total success: 0 of 115    \n",
      "reset due to  too high  Episode reward:  -75.38671875 total success: 0 of 116      \n",
      "reset due to  too high  Episode reward:  -75.4541015625 total success: 0 of 117    \n",
      "reset due to  too high  Episode reward:  -75.3447265625 total success: 0 of 118    \n",
      "reset due to  too high  Episode reward:  -75.322265625 total success: 0 of 119     \n",
      "reset due to  too high  Episode reward:  -75.3759765625 total success: 0 of 120    \n",
      "reset due to  too high  Episode reward:  -70.4697265625 total success: 0 of 121    \n",
      "reset due to  too high  Episode reward:  -75.34765625 total success: 0 of 122      \n",
      "reset due to  too high  Episode reward:  -23.494140625 total success: 0 of 123     \n",
      "reset due to  collision  Episode reward:  -23.11767578125 total success: 0 of 124  \n",
      "reset due to  collision  Episode reward:  -60.041015625 total success: 0 of 125    \n",
      "reset due to  collision  Episode reward:  -60.42529296875 total success: 0 of 126  \n",
      "reset due to  collision  Episode reward:  -56.955078125 total success: 0 of 127    \n",
      "reset due to  too high  Episode reward:  -66.998046875 total success: 0 of 128     \n",
      "reset due to  collision  Episode reward:  -60.0576171875 total success: 0 of 129   \n",
      "reset due to  collision  Episode reward:  -61.224609375 total success: 0 of 130    \n",
      "reset due to  collision  Episode reward:  -60.96435546875 total success: 0 of 131  \n",
      "reset due to  collision  Episode reward:  -58.7762451171875 total success: 0 of 132\n",
      "reset due to  collision  Episode reward:  -18.5419921875 total success: 0 of 133   \n",
      "reset due to  collision  Episode reward:  -59.87744140625 total success: 0 of 134  \n",
      "reset due to  collision  Episode reward:  -59.00927734375 total success: 0 of 135  \n",
      "reset due to  collision  Episode reward:  -59.113525390625 total success: 0 of 136 \n",
      "reset due to  collision  Episode reward:  -58.711181640625 total success: 0 of 137 \n",
      "reset due to  collision  Episode reward:  -56.80859375 total success: 0 of 138     \n",
      "reset due to  collision  Episode reward:  -60.44189453125 total success: 0 of 139  \n",
      "reset due to  collision  Episode reward:  -60.54248046875 total success: 0 of 140  \n",
      "reset due to  collision  Episode reward:  -61.16943359375 total success: 0 of 141  \n",
      "reset due to  collision  Episode reward:  -59.5 total success: 0 of 142            \n",
      "reset due to  collision  Episode reward:  -58.696044921875 total success: 0 of 143 \n",
      "reset due to  collision  Episode reward:  -58.138671875 total success: 0 of 144    \n",
      "reset due to  collision  Episode reward:  -58.69970703125 total success: 0 of 145  \n",
      "reset due to  collision  Episode reward:  -59.68798828125 total success: 0 of 146  \n",
      "reset due to  too high  Episode reward:  -58.564453125 total success: 0 of 147     \n",
      "reset due to  too high  Episode reward:  -70.4580078125 total success: 0 of 148    \n",
      "reset due to  too high  Episode reward:  -75.3876953125 total success: 0 of 149    \n",
      "reset due to  too high  Episode reward:  -75.244140625 total success: 0 of 150     \n",
      "reset due to  collision  Episode reward:  -62.50732421875 total success: 0 of 151  \n",
      "reset due to  too high  Episode reward:  -73.3798828125 total success: 0 of 152    \n",
      "reset due to  too high  Episode reward:  -75.3427734375 total success: 0 of 153    \n",
      "reset due to  too high  Episode reward:  -75.484375 total success: 0 of 154        \n",
      "reset due to  too high  Episode reward:  -75.2724609375 total success: 0 of 155    \n",
      "reset due to  too high  Episode reward:  -75.365234375 total success: 0 of 156     \n",
      "reset due to  too high  Episode reward:  -79.15625 total success: 0 of 157         \n",
      "reset due to  too high  Episode reward:  -75.4296875 total success: 0 of 158       \n",
      "reset due to  too high  Episode reward:  -75.4033203125 total success: 0 of 159    \n",
      "reset due to  collision  Episode reward:  -58.783447265625 total success: 0 of 160 \n",
      "reset due to  collision  Episode reward:  -59.599365234375 total success: 0 of 161 \n",
      "reset due to  collision  Episode reward:  -23.29052734375 total success: 0 of 162  \n",
      "reset due to  too high  Episode reward:  -47.556640625 total success: 0 of 163     \n",
      "reset due to  too high  Episode reward:  -70.470703125 total success: 0 of 164     \n",
      "reset due to  collision  Episode reward:  -64.8330078125 total success: 0 of 165   \n",
      "reset due to  collision  Episode reward:  -59.068603515625 total success: 0 of 166 \n",
      "reset due to  collision  Episode reward:  -57.43798828125 total success: 0 of 167  \n",
      "reset due to  too high  Episode reward:  -73.431640625 total success: 0 of 168     \n",
      "reset due to  too high  Episode reward:  -75.4677734375 total success: 0 of 169    \n",
      "reset due to  too high  Episode reward:  -75.314453125 total success: 0 of 170     \n",
      "reset due to  too high  Episode reward:  -72.32275390625 total success: 0 of 171   \n",
      "reset due to  too high  Episode reward:  -75.3330078125 total success: 0 of 172    \n",
      "reset due to  too high  Episode reward:  -73.4345703125 total success: 0 of 173    \n",
      "reset due to  too high  Episode reward:  -74.927734375 total success: 0 of 174     \n",
      "reset due to  too high  Episode reward:  -72.33251953125 total success: 0 of 175   \n",
      "reset due to  too high  Episode reward:  -73.3818359375 total success: 0 of 176    \n",
      "reset due to  too high  Episode reward:  -75.3837890625 total success: 0 of 177    \n",
      "reset due to  collision  Episode reward:  -60.3701171875 total success: 0 of 178   \n",
      "reset due to  collision  Episode reward:  -57.36083984375 total success: 0 of 179  \n",
      "reset due to  collision  Episode reward:  -58.89208984375 total success: 0 of 180  \n",
      "reset due to  collision  Episode reward:  -58.904052734375 total success: 0 of 181 \n",
      "reset due to  collision  Episode reward:  -60.6474609375 total success: 0 of 182   \n",
      "reset due to  collision  Episode reward:  -58.950439453125 total success: 0 of 183 \n",
      "reset due to  collision  Episode reward:  -59.520263671875 total success: 0 of 184 \n",
      "reset due to  collision  Episode reward:  -58.19921875 total success: 0 of 185     \n",
      "reset due to  collision  Episode reward:  -59.833251953125 total success: 0 of 186 \n",
      "reset due to  collision  Episode reward:  -62.2890625 total success: 0 of 187      \n",
      "reset due to  collision  Episode reward:  -61.29541015625 total success: 0 of 188  \n",
      "reset due to  collision  Episode reward:  -59.624267578125 total success: 0 of 189 \n",
      "reset due to  too high  Episode reward:  -39.7578125 total success: 0 of 190       \n",
      "reset due to  collision  Episode reward:  -66.2403564453125 total success: 0 of 191\n",
      "reset due to  collision  Episode reward:  -58.87548828125 total success: 0 of 192  \n",
      "reset due to  collision  Episode reward:  -60.06005859375 total success: 0 of 193  \n",
      "reset due to  collision  Episode reward:  -61.28515625 total success: 0 of 194     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset due to  collision  Episode reward:  -54.40625 total success: 0 of 195        \n",
      "reset due to  collision  Episode reward:  -59.68701171875 total success: 0 of 196  \n",
      "reset due to  collision  Episode reward:  -60.77587890625 total success: 0 of 197  \n",
      "reset due to  collision  Episode reward:  -62.9521484375 total success: 0 of 198   \n",
      "reset due to  collision  Episode reward:  -59.89404296875 total success: 0 of 199  \n",
      "reset due to  collision  Episode reward:  -59.974609375 total success: 0 of 200    \n",
      "reset due to  collision  Episode reward:  -60.41455078125 total success: 0 of 201  \n",
      "reset due to  collision  Episode reward:  -57.75439453125 total success: 0 of 202  \n",
      "reset due to  collision  Episode reward:  -60.126953125 total success: 0 of 203    \n",
      "reset due to  collision  Episode reward:  -60.1142578125 total success: 0 of 204   \n",
      "reset due to  too high  Episode reward:  -45.3544921875 total success: 0 of 205    \n",
      "reset due to  too high  Episode reward:  -73.4501953125 total success: 0 of 206    \n",
      "reset due to  too high  Episode reward:  -75.3515625 total success: 0 of 207       \n",
      "reset due to  too high  Episode reward:  -75.3330078125 total success: 0 of 208    \n",
      "reset due to  too high  Episode reward:  -70.4384765625 total success: 0 of 209    \n",
      "reset due to  collision  Episode reward:  -61.828369140625 total success: 0 of 210 \n",
      "reset due to  collision  Episode reward:  -62.677734375 total success: 0 of 211    \n",
      "reset due to  collision  Episode reward:  -58.831787109375 total success: 0 of 212 \n",
      "reset due to  collision  Episode reward:  -60.505859375 total success: 0 of 213    \n",
      "reset due to  too high  Episode reward:  -46.5615234375 total success: 0 of 214    \n",
      "reset due to  too high  Episode reward:  -75.3359375 total success: 0 of 215       \n",
      "reset due to  too high  Episode reward:  -75.373046875 total success: 0 of 216     \n",
      "reset due to  too high  Episode reward:  -75.33203125 total success: 0 of 217      \n",
      "reset due to  too high  Episode reward:  -75.32421875 total success: 0 of 218      \n",
      "reset due to  too high  Episode reward:  -77.341796875 total success: 0 of 219     \n",
      "reset due to  collision  Episode reward:  -64.244140625 total success: 0 of 220    \n",
      "reset due to  collision  Episode reward:  -58.811767578125 total success: 0 of 221 \n",
      "reset due to  too high  Episode reward:  -63.7607421875 total success: 0 of 222    \n",
      "reset due to  collision  Episode reward:  -59.6796875 total success: 0 of 223      \n",
      "reset due to  collision  Episode reward:  -60.19140625 total success: 0 of 224     \n",
      "reset due to  collision  Episode reward:  -59.732421875 total success: 0 of 225    \n",
      "reset due to  collision  Episode reward:  -58.825927734375 total success: 0 of 226 \n",
      "reset due to  collision  Episode reward:  -59.75390625 total success: 0 of 227     \n",
      "reset due to  collision  Episode reward:  -64.35498046875 total success: 0 of 228  \n",
      "reset due to  collision  Episode reward:  -55.672607421875 total success: 0 of 229 \n",
      "reset due to  collision  Episode reward:  -57.118408203125 total success: 0 of 230 \n",
      "reset due to  collision  Episode reward:  -58.788818359375 total success: 0 of 231 \n",
      "reset due to  collision  Episode reward:  -61.341796875 total success: 0 of 232    \n",
      "reset due to  collision  Episode reward:  -60.939453125 total success: 0 of 233    \n",
      "reset due to  collision  Episode reward:  -59.5537109375 total success: 0 of 234   \n",
      "reset due to  collision  Episode reward:  -58.988525390625 total success: 0 of 235 \n",
      "reset due to  collision  Episode reward:  -61.29150390625 total success: 0 of 236  \n",
      "reset due to  collision  Episode reward:  -59.010986328125 total success: 0 of 237 \n",
      "reset due to  collision  Episode reward:  -57.681884765625 total success: 0 of 238 \n",
      "reset due to  collision  Episode reward:  -58.767822265625 total success: 0 of 239 \n",
      "reset due to  collision  Episode reward:  -60.1943359375 total success: 0 of 240   \n",
      "reset due to  collision  Episode reward:  -57.253662109375 total success: 0 of 241 \n",
      "reset due to  collision  Episode reward:  -59.892578125 total success: 0 of 242    \n",
      "reset due to  collision  Episode reward:  -59.713134765625 total success: 0 of 243 \n",
      "reset due to  too high  Episode reward:  -38.37841796875 total success: 0 of 244   \n",
      "reset due to  too high  Episode reward:  -73.4228515625 total success: 0 of 245    \n",
      "reset due to  too high  Episode reward:  -75.3330078125 total success: 0 of 246    \n",
      "reset due to  too high  Episode reward:  -75.7685546875 total success: 0 of 247    \n",
      "reset due to  too high  Episode reward:  -75.369140625 total success: 0 of 248     \n",
      "reset due to  too high  Episode reward:  -75.3193359375 total success: 0 of 249    \n",
      "reset due to  collision  Episode reward:  -66.30859375 total success: 0 of 250     \n",
      "reset due to  collision  Episode reward:  -61.3671875 total success: 0 of 251      \n",
      "reset due to  collision  Episode reward:  -58.911376953125 total success: 0 of 252 \n",
      "reset due to  collision  Episode reward:  -58.539794921875 total success: 0 of 253 \n",
      "reset due to  collision  Episode reward:  -61.642333984375 total success: 0 of 254 \n",
      "reset due to  collision  Episode reward:  -60.22021484375 total success: 0 of 255  \n",
      "reset due to  collision  Episode reward:  -60.01513671875 total success: 0 of 256  \n",
      "reset due to  collision  Episode reward:  -61.3984375 total success: 0 of 257      \n",
      "reset due to  too high  Episode reward:  -58.8134765625 total success: 0 of 258    \n",
      "reset due to  too high  Episode reward:  -75.32421875 total success: 0 of 259      \n",
      "reset due to  too high  Episode reward:  -70.48046875 total success: 0 of 260      \n",
      "reset due to  too high  Episode reward:  -75.3359375 total success: 0 of 261       \n",
      "reset due to  too high  Episode reward:  -75.337890625 total success: 0 of 262     \n",
      "reset due to  collision  Episode reward:  -63.9716796875 total success: 0 of 263   \n",
      "reset due to  collision  Episode reward:  -60.29541015625 total success: 0 of 264  \n",
      "reset due to  too high  Episode reward:  -73.3759765625 total success: 0 of 265    \n",
      "reset due to  too high  Episode reward:  -71.068359375 total success: 0 of 266     \n",
      "reset due to  too high  Episode reward:  -75.4306640625 total success: 0 of 267    \n",
      "reset due to  too high  Episode reward:  -75.4296875 total success: 0 of 268       \n",
      "reset due to  too high  Episode reward:  -75.357421875 total success: 0 of 269     \n",
      "reset due to  too high  Episode reward:  -55.5263671875 total success: 0 of 270    \n",
      "reset due to  too high  Episode reward:  -75.4111328125 total success: 0 of 271    \n",
      "reset due to  too high  Episode reward:  -75.353515625 total success: 0 of 272     \n",
      "reset due to  too high  Episode reward:  -66.322265625 total success: 0 of 273     \n",
      "reset due to  too high  Episode reward:  -75.3603515625 total success: 0 of 274    \n",
      "reset due to  too high  Episode reward:  -75.45703125 total success: 0 of 275      \n",
      "reset due to  too high  Episode reward:  -75.3349609375 total success: 0 of 276    \n",
      "reset due to  too high  Episode reward:  -65.06640625 total success: 0 of 277      \n",
      "reset due to  too high  Episode reward:  -75.35546875 total success: 0 of 278      \n",
      "reset due to  too high  Episode reward:  -70.3408203125 total success: 0 of 279    \n",
      "reset due to  too high  Episode reward:  -75.4052734375 total success: 0 of 280    \n",
      "reset due to  too high  Episode reward:  -73.53125 total success: 0 of 281         \n",
      "reset due to  too high  Episode reward:  -75.4580078125 total success: 0 of 282    \n",
      "reset due to  too high  Episode reward:  -79.33984375 total success: 0 of 283      \n",
      "reset due to  collision  Episode reward:  -62.3759765625 total success: 0 of 284   \n",
      "reset due to  collision  Episode reward:  -59.9794921875 total success: 0 of 285   \n",
      "reset due to  too high  Episode reward:  -55.5625 total success: 0 of 286          \n",
      "reset due to  collision  Episode reward:  -62.8408203125 total success: 0 of 287   \n",
      "reset due to  collision  Episode reward:  -59.588623046875 total success: 0 of 288 \n",
      "reset due to  collision  Episode reward:  -59.72509765625 total success: 0 of 289  \n",
      "reset due to  too high  Episode reward:  -39.8115234375 total success: 0 of 290    \n",
      "reset due to  too high  Episode reward:  -75.37109375 total success: 0 of 291      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset due to  collision  Episode reward:  -64.98388671875 total success: 0 of 292  \n",
      "reset due to  too high  Episode reward:  -63.9365234375 total success: 0 of 293    \n",
      "reset due to  too high  Episode reward:  -79.2255859375 total success: 0 of 294    \n",
      "reset due to  too high  Episode reward:  -75.4775390625 total success: 0 of 295    \n",
      "reset due to  too high  Episode reward:  -75.4453125 total success: 0 of 296       \n",
      "reset due to  collision  Episode reward:  -62.691162109375 total success: 0 of 297 \n",
      "reset due to  collision  Episode reward:  -61.294921875 total success: 0 of 298    \n",
      "reset due to  too high  Episode reward:  -73.5615234375 total success: 0 of 299    \n",
      "reset due to  collision  Episode reward:  -61.18798828125 total success: 0 of 300  \n",
      "reset due to  collision  Episode reward:  -61.31689453125 total success: 0 of 301  \n",
      "reset due to  collision  Episode reward:  -58.95458984375 total success: 0 of 302  \n",
      "reset due to  collision  Episode reward:  -58.0576171875 total success: 0 of 303   \n",
      "reset due to  collision  Episode reward:  -60.4521484375 total success: 0 of 304   \n",
      "reset due to  collision  Episode reward:  -92.265625 total success: 0 of 305       \n",
      "reset due to  too high  Episode reward:  -77.314453125 total success: 0 of 306     \n",
      "reset due to  too high  Episode reward:  -75.2177734375 total success: 0 of 307    \n",
      "reset due to  too high  Episode reward:  -75.435546875 total success: 0 of 308     \n",
      "reset due to  too high  Episode reward:  -75.4560546875 total success: 0 of 309    \n",
      "reset due to  too high  Episode reward:  -75.2978515625 total success: 0 of 310    \n",
      "reset due to  collision  Episode reward:  -62.4521484375 total success: 0 of 311   \n",
      "reset due to  collision  Episode reward:  -59.8232421875 total success: 0 of 312   \n",
      "reset due to  collision  Episode reward:  -59.555419921875 total success: 0 of 313 \n",
      "reset due to  collision  Episode reward:  -58.84912109375 total success: 0 of 314  \n",
      "reset due to  collision  Episode reward:  -59.5986328125 total success: 0 of 315   \n",
      "reset due to  collision  Episode reward:  -55.52978515625 total success: 0 of 316  \n",
      "reset due to  collision  Episode reward:  -54.213623046875 total success: 0 of 317 \n",
      "reset due to  collision  Episode reward:  -60.48876953125 total success: 0 of 318  \n",
      "reset due to  collision  Episode reward:  -58.768798828125 total success: 0 of 319 \n",
      "reset due to  collision  Episode reward:  -59.614501953125 total success: 0 of 320 \n",
      "reset due to  collision  Episode reward:  -60.57568359375 total success: 0 of 321  \n",
      "reset due to  collision  Episode reward:  -58.753662109375 total success: 0 of 322 \n",
      "reset due to  collision  Episode reward:  -58.6044921875 total success: 0 of 323   \n",
      "reset due to  collision  Episode reward:  -60.310302734375 total success: 0 of 324 \n",
      "reset due to  collision  Episode reward:  -60.308837890625 total success: 0 of 325 \n",
      "reset due to  collision  Episode reward:  -61.48583984375 total success: 0 of 326  \n",
      "reset due to  collision  Episode reward:  -59.94775390625 total success: 0 of 327  \n",
      "reset due to  collision  Episode reward:  -61.775390625 total success: 0 of 328    \n",
      "reset due to  collision  Episode reward:  -59.6044921875 total success: 0 of 329   \n",
      "reset due to  too high  Episode reward:  -58.810546875 total success: 0 of 330     \n",
      "reset due to  collision  Episode reward:  -23.17724609375 total success: 0 of 331  \n",
      "reset due to  too high  Episode reward:  -73.427734375 total success: 0 of 332     \n",
      "reset due to  collision  Episode reward:  -59.956298828125 total success: 0 of 333 \n",
      "reset due to  collision  Episode reward:  -61.11474609375 total success: 0 of 334  \n",
      "reset due to  collision  Episode reward:  -60.1640625 total success: 0 of 335      \n",
      "reset due to  collision  Episode reward:  -59.08642578125 total success: 0 of 336  \n",
      "reset due to  collision  Episode reward:  -58.99658203125 total success: 0 of 337  \n",
      "reset due to  collision  Episode reward:  -58.77978515625 total success: 0 of 338  \n",
      "reset due to  collision  Episode reward:  -60.11767578125 total success: 0 of 339  \n",
      "reset due to  collision  Episode reward:  -55.562744140625 total success: 0 of 340 \n",
      "reset due to  collision  Episode reward:  -59.625244140625 total success: 0 of 341 \n",
      "reset due to  collision  Episode reward:  -58.74072265625 total success: 0 of 342  \n",
      "reset due to  collision  Episode reward:  -59.670166015625 total success: 0 of 343 \n",
      "reset due to  collision  Episode reward:  -57.208984375 total success: 0 of 344    \n",
      "reset due to  collision  Episode reward:  -61.2744140625 total success: 0 of 345   \n",
      "reset due to  collision  Episode reward:  -61.34716796875 total success: 0 of 346  \n",
      "reset due to  collision  Episode reward:  -61.650146484375 total success: 0 of 347 \n",
      "reset due to  collision  Episode reward:  -61.21533203125 total success: 0 of 348  \n",
      "reset due to  collision  Episode reward:  -59.68310546875 total success: 0 of 349  \n",
      "reset due to  collision  Episode reward:  -57.216796875 total success: 0 of 350    \n",
      "reset due to  collision  Episode reward:  -54.3447265625 total success: 0 of 351   \n",
      "reset due to  collision  Episode reward:  -61.0673828125 total success: 0 of 352   \n",
      "reset due to  collision  Episode reward:  -61.705078125 total success: 0 of 353    \n",
      "reset due to  collision  Episode reward:  -60.14990234375 total success: 0 of 354  \n",
      "reset due to  collision  Episode reward:  -20.3994140625 total success: 0 of 355   \n",
      "reset due to  collision  Episode reward:  -61.708984375 total success: 0 of 356    \n",
      "reset due to  collision  Episode reward:  -62.6904296875 total success: 0 of 357   \n",
      "reset due to  too high  Episode reward:  -69.7421875 total success: 0 of 358       \n",
      "reset due to  collision  Episode reward:  -62.42529296875 total success: 0 of 359  \n",
      "reset due to  collision  Episode reward:  -59.707763671875 total success: 0 of 360 \n",
      "reset due to  collision  Episode reward:  -59.123046875 total success: 0 of 361    \n",
      "reset due to  collision  Episode reward:  -59.884765625 total success: 0 of 362    \n",
      "reset due to  collision  Episode reward:  -59.92138671875 total success: 0 of 363  \n",
      "reset due to  collision  Episode reward:  -58.28466796875 total success: 0 of 364  \n",
      "reset due to  collision  Episode reward:  -61.3623046875 total success: 0 of 365   \n",
      "reset due to  collision  Episode reward:  -60.1474609375 total success: 0 of 366   \n",
      "reset due to  collision  Episode reward:  -60.0556640625 total success: 0 of 367   \n",
      "reset due to  collision  Episode reward:  -60.16845703125 total success: 0 of 368  \n",
      "reset due to  collision  Episode reward:  -61.833251953125 total success: 0 of 369 \n",
      "reset due to  collision  Episode reward:  -58.219970703125 total success: 0 of 370 \n",
      "reset due to  collision  Episode reward:  -60.69775390625 total success: 0 of 371  \n",
      "reset due to  collision  Episode reward:  -61.13671875 total success: 0 of 372     \n",
      "reset due to  collision  Episode reward:  -60.4716796875 total success: 0 of 373   \n",
      "reset due to  collision  Episode reward:  -61.0546875 total success: 0 of 374      \n",
      "reset due to  collision  Episode reward:  -55.815673828125 total success: 0 of 375 \n",
      "reset due to  collision  Episode reward:  -61.21923828125 total success: 0 of 376  \n",
      "reset due to  collision  Episode reward:  -59.793212890625 total success: 0 of 377 \n",
      "reset due to  collision  Episode reward:  -60.73193359375 total success: 0 of 378  \n",
      "reset due to  collision  Episode reward:  -61.552734375 total success: 0 of 379    \n",
      "reset due to  collision  Episode reward:  -56.8212890625 total success: 0 of 380   \n",
      "reset due to  collision  Episode reward:  -60.2060546875 total success: 0 of 381   \n",
      "reset due to  collision  Episode reward:  -59.062744140625 total success: 0 of 382 \n",
      "reset due to  collision  Episode reward:  -58.03271484375 total success: 0 of 383  \n",
      "reset due to  collision  Episode reward:  -56.842041015625 total success: 0 of 384 \n",
      "reset due to  too high  Episode reward:  -47.1640625 total success: 0 of 385       \n",
      "reset due to  collision  Episode reward:  -19.72802734375 total success: 0 of 386  \n",
      "reset due to  collision  Episode reward:  -61.600341796875 total success: 0 of 387 \n",
      "reset due to  collision  Episode reward:  -58.195068359375 total success: 0 of 388 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset due to  collision  Episode reward:  -60.30078125 total success: 0 of 389     \n",
      "reset due to  collision  Episode reward:  -59.634033203125 total success: 0 of 390 \n",
      "reset due to  collision  Episode reward:  -60.85009765625 total success: 0 of 391  \n",
      "reset due to  collision  Episode reward:  -55.488037109375 total success: 0 of 392 \n",
      "reset due to  collision  Episode reward:  -61.25537109375 total success: 0 of 393  \n",
      "reset due to  collision  Episode reward:  -58.861572265625 total success: 0 of 394 \n",
      "reset due to  collision  Episode reward:  -59.5908203125 total success: 0 of 395   \n",
      "reset due to  collision  Episode reward:  -61.27099609375 total success: 0 of 396  \n",
      "action: 0            height: -14.45       reward: 3.00000.     steps: 16           \r"
     ]
    }
   ],
   "source": [
    "episode_step = 0\n",
    "total_step = 0\n",
    "episode = 0\n",
    "episode_reward = 0\n",
    "total_success = 0\n",
    "reward_list = []\n",
    "\n",
    "s = env.reset()\n",
    "while True:\n",
    "    \n",
    "    action = RL.choose_action(s)\n",
    "    \n",
    "    s_,r,done,info = env.step(action)\n",
    "    \n",
    "    #env.render(extra1 = str(count),extra2 = \"reward: \"+str(int(r))+\" Done: \"+str(succ)+\" Episode: \"+str(episode))\n",
    "    print (\"action: {}\".format(action).ljust(20,\" \"),\"height: {:.2f}\".format(env.getPos()[2]).ljust(20,\" \"), \"reward: {:.5f}.\".format(r).ljust(20,\" \"),\"steps: {}\".format(episode_step).ljust(20,\" \"),end = \"\\r\")\n",
    "    \n",
    "    episode_step += 1\n",
    "    total_step += 1\n",
    "    episode_reward += r\n",
    "    RL.add_data(s, action, r, s_,done)\n",
    "    \n",
    "    if done:\n",
    "        if info == \"success\":\n",
    "            total_success += 1\n",
    "        episode += 1\n",
    "        RL.model.save(\"temp/temp.h5\")\n",
    "        reward_list.append(episode_reward)\n",
    "        print (\" \"*80,end = '\\r')\n",
    "        print (\"reset due to \",info,\" Episode reward: \",episode_reward,\"total success: {} of {}\".format(total_success,episode))\n",
    "        episode_step = 0\n",
    "        episode_reward = 0\n",
    "        if episode >= 5000:\n",
    "            break\n",
    "        env.reset()\n",
    "        \n",
    "    if total_step > 1:\n",
    "        RL.learn(times = 2)\n",
    "    \n",
    "\n",
    "        \n",
    "    s = s_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RL.model.predict(np.array([s]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RL.model.save(\"temp/IMG_r+-1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = EnvImgControl(aim = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_step = 0\n",
    "total_step = 0\n",
    "episode = 0\n",
    "episode_reward = 0\n",
    "total_success = 0\n",
    "reward_list = []\n",
    "\n",
    "s = env.reset()\n",
    "while True:\n",
    "    \n",
    "    action = RL.choose_action(s)\n",
    "    \n",
    "    s_,r,done,info = env.step(action)\n",
    "    \n",
    "    #env.render(extra1 = str(count),extra2 = \"reward: \"+str(int(r))+\" Done: \"+str(succ)+\" Episode: \"+str(episode))\n",
    "    print (\"action: {}\".format(action).ljust(20,\" \"),\"height: {:.2f}\".format(env.getPos()[2]).ljust(20,\" \"), \"reward: {:.5f}.\".format(r).ljust(20,\" \"),\"steps: {}\".format(episode_step).ljust(20,\" \"),end = \"\\r\")\n",
    "    \n",
    "    episode_step += 1\n",
    "    total_step += 1\n",
    "    episode_reward += r\n",
    "    RL.add_data(s, action, r, s_,done)\n",
    "    \n",
    "    if done:\n",
    "        if info == \"success\":\n",
    "            total_success += 1\n",
    "        episode += 1\n",
    "        RL.model.save(\"temp/temp1.h5\")\n",
    "        reward_list.append(episode_reward)\n",
    "        print (\" \"*80,end = '\\r')\n",
    "        print (\"reset due to \",info,\" Episode reward: \",episode_reward,\"total success: {} of {}\".format(total_success,episode))\n",
    "        episode_step = 0\n",
    "        episode_reward = 0\n",
    "        if episode >= 500:\n",
    "            break\n",
    "        env.reset()\n",
    "        \n",
    "    if total_step > 1:\n",
    "        RL.learn(times = 2)\n",
    "    \n",
    "\n",
    "        \n",
    "    s = s_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
